{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mouse::FCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXJlTU_82goy",
        "colab_type": "text"
      },
      "source": [
        "## CUSTOMIZATION\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJvzTXc2ZqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "# подключить GPU: Runtime -> Change runtime type -> Hardware accelerator: GPU\n",
        "# вывouyод: '/device:GPU:0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhpfF8Si2hnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# монтируем гугл диск"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-vdOD0k2soZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# копируем и разархивируем файлы в colab\n",
        "! cp /content/gdrive/'My Drive'/Mouse/dataset.zip . # тут точка!\n",
        "! unzip -q dataset\n",
        "! rm dataset.zip\n",
        "! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9rxyKrdzFiV",
        "colab_type": "text"
      },
      "source": [
        "## FCNN\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CixxBLpm3EgT",
        "colab_type": "text"
      },
      "source": [
        "### Libraries\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJHyJmI926db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model, save_model, load_model\n",
        "from tensorflow.keras.layers import (Input, Conv1D, UpSampling1D, MaxPool1D,\n",
        "                                     BatchNormalization, Dropout, ReLU)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import logcosh, mean_squared_error\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import glob\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "winuTR7V3mIX",
        "colab_type": "text"
      },
      "source": [
        "### Global variables\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHQ7LR6L3d5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EXPERIMENT = 1\n",
        "\n",
        "MODEL_NAME = f'{N_EXPERIMENT}_mouse_model'\n",
        "WEIGHT_NAME = f'{N_EXPERIMENT}_mouse_weight'\n",
        "LOG_NAME = f'{N_EXPERIMENT}_training_log.csv'\n",
        "GDRIVE_PATH = f'./gdrive/My Drive/Mouse/{N_EXPERIMENT}'\n",
        "CHECKPOINT_PATH = f'{GDRIVE_PATH}/{WEIGHT_NAME}''_{epoch:03d}_loss-{loss:.3f}_valloss-{val_loss:.3f}.h5'\n",
        "N_FEATURES = 79\n",
        "BATCH_SIZE = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5tBlnKxv-NP",
        "colab_type": "text"
      },
      "source": [
        "### Load data\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvbMd4r4CatD",
        "colab_type": "text"
      },
      "source": [
        "Option:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYtwUjGFHRZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET = 'BALABIT'\n",
        "USERNAME = 'user07'\n",
        "SESSION = 'session_all'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LExk97j1wAqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(dataset: str,\n",
        "              username: str,\n",
        "              session: str,\n",
        "              mode: str,\n",
        "              legal: bool = True) -> np.array:\n",
        "    if legal:\n",
        "        path = f\"./dataset/{dataset}/{mode}_features/{username}/{session}\"\n",
        "        X = pd.read_csv(path, sep=',', header=None).values\n",
        "    else:\n",
        "        X = None\n",
        "        for path in glob.glob(f\"./dataset/{dataset}/{mode}_features/user*\"):\n",
        "            if os.path.basename(path) == username:\n",
        "                continue\n",
        "            session_path = os.path.join(path, session)\n",
        "            features = pd.read_csv(session_path, sep=',', header=None).values\n",
        "            X = np.vstack((X, features)) if X is not None else features\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18xUgi9eCep1",
        "colab_type": "text"
      },
      "source": [
        "Train data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUA0zccmzmSF",
        "colab_type": "code",
        "outputId": "656acd3d-c1c6-452f-c169-e1401f020298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = load_data(DATASET, USERNAME, SESSION, 'train')\n",
        "N_FEATURES = X.shape[1]\n",
        "print(f\"Train data shape: {X.shape}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape: (3417, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCaHuiJzCgJw",
        "colab_type": "text"
      },
      "source": [
        "Validation data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0a-4MWyrRCz",
        "colab_type": "code",
        "outputId": "dbae1a31-f8f1-49f6-eced-a04cfc9ba9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_valid = load_data(DATASET, USERNAME, SESSION, 'test')\n",
        "print(f\"Validation data shape: {X_valid.shape}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation data shape: (3457, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFs7r8fqDuh4",
        "colab_type": "text"
      },
      "source": [
        "### Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXtA5yDY5Rpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import RepeatVector, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "degDDEAGDwCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(n_features): # \"FCNN\"\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(n_features, )))\n",
        "    model.add(RepeatVector(n_features))\n",
        "\n",
        "    model.add(Conv1D(256, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(256, 3, padding='same', activation=ReLU()))\n",
        "    model.add(MaxPool1D())\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv1D(128, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(128, 3, padding='same', activation=ReLU()))\n",
        "    model.add(MaxPool1D())\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv1D(64, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(64, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(64, 3, padding='same', activation=ReLU()))\n",
        "    model.add(MaxPool1D())\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv1D(32, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(32, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(32, 3, padding='same', activation=ReLU()))\n",
        "    model.add(MaxPool1D())\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(UpSampling1D())\n",
        "    model.add(Conv1D(32, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(32, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(32, 3, padding='same', activation=ReLU()))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(UpSampling1D())\n",
        "    model.add(Conv1D(64, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(64, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(64, 3, padding='same', activation=ReLU()))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(UpSampling1D())\n",
        "    model.add(Conv1D(128, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(128, 3, padding='same', activation=ReLU()))\n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(UpSampling1D())\n",
        "    model.add(Conv1D(256, 3, padding='same', activation=ReLU()))\n",
        "    model.add(Conv1D(256, 3, padding='same', activation=ReLU()))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=256, activation=ReLU()))\n",
        "    model.add(Dense(units=n_features))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmLdxSA_IeDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(N_FEATURES)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8X4euc21r00",
        "colab_type": "text"
      },
      "source": [
        "Compile:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssVmxBZH1qMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(lr=0.001),\n",
        "              loss=logcosh,\n",
        "              metrics=['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogyAYQAY8qAB",
        "colab_type": "text"
      },
      "source": [
        "Callbacks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMUNr8QQvnZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=CHECKPOINT_PATH, monitor='val_loss',\n",
        "                               verbose=1, save_best_only=True,\n",
        "                               save_weights_only=True, mode='min')\n",
        "logger = CSVLogger(LOG_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak-s_0GvGFG3",
        "colab_type": "text"
      },
      "source": [
        "Fit:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otQvsKYk8s5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[:, :], X[:, :],\n",
        "          batch_size=16,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "        #   callbacks=[logger, checkpointer],\n",
        "          validation_data=(X_valid[:, :], X_valid[:, :]),\n",
        "          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6op9QjFeGTiS",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGzPA1zK1zzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test, X_test = load_data(DATASET, USERNAME, SESSION, 'train',\n",
        "                           legal=False, timesteps=timesteps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de5AdgysA2yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}